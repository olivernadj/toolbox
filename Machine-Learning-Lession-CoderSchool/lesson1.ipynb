{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 - Fundamentals (part 1)\n",
    "\n",
    "**Goal**\n",
    "After this first lesson, you should:\n",
    "1. Know how to setup a working python environment on your computer using anaconda\n",
    "2. Understand the following concepts:\n",
    "    - variance\n",
    "    - bias\n",
    "    - overfitting\n",
    "    - underfitting\n",
    "-----\n",
    "\n",
    "### Setting up Python\n",
    "\n",
    "If you have not already setup a python environment, you should do so know:\n",
    "\n",
    "**MacOs installation**\n",
    "https://conda.io/docs/user-guide/install/macos.html\n",
    "\n",
    "**Windows installation**\n",
    "https://conda.io/docs/user-guide/install/windows.html\n",
    "\n",
    "You can test that you succeeded by opening a terminal prompt and typing:\n",
    "\n",
    "    jupyter notebook\n",
    "    \n",
    "Success will open a new tab in your default browser which has a notebook that looks like this one\n",
    "\n",
    "### Understanding Numpy and Pandas\n",
    "\n",
    "[numpy](http://www.numpy.org/) and [pandas](https://pandas.pydata.org/) are libraries which help manipulate data in a structured manner. These libraries provide datastructures and algorithms that help manipulate data.\n",
    "\n",
    "Since we installed numpy and pandas using anaconda and the [conda package manager](https://conda.io/docs/index.html), we have access to all the libraries we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we always need to include our libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 2., 0., 0.],\n",
       "       [0., 0., 3., 0.],\n",
       "       [0., 0., 0., 4.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's learn some basic operations with the numpy library\n",
    "########################\n",
    "\n",
    "# Create a 1D array\n",
    "a = np.array([1,2,3,4])\n",
    "\n",
    "# Create a 2D matrix\n",
    "b = np.matrix([[1,2],[3,4]])\n",
    "\n",
    "# Create a 2D identity matrix with 4 rows\n",
    "c = np.eye(4)\n",
    "\n",
    "# Scalar multiplication\n",
    "5 * a\n",
    "\n",
    "# matrix multiplication\n",
    "a * c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and perform the following matrix calculation using numpy.\n",
    "\n",
    "Calculate $A$, where $\n",
    "A = \n",
    "   \\begin{bmatrix} \n",
    "      0 & 1 \\\\\n",
    "      1 & 0 \\\\ \n",
    "   \\end{bmatrix}\n",
    "   \\begin{bmatrix}\n",
    "      3 \\\\\n",
    "      4 \\\\\n",
    "   \\end{bmatrix}\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-3539b5736217>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-3539b5736217>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    A = # FILL IN YOUR SOLUTION HERE\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Answer\n",
    "A = # FILL IN YOUR SOLUTION HERE\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many algorithms which numpy provides.\n",
    "######################\n",
    "\n",
    "# Take the dot product of two arrays\n",
    "arr1 = np.array([1,2,3])\n",
    "arr2 = np.array([4,5,6])\n",
    "\n",
    "np.dot(arr1,arr2)\n",
    "\n",
    "# Generate an array from a specified range\n",
    "arr3 = np.arange(10)\n",
    "\n",
    "# Shuffle an array\n",
    "np.random.shuffle(arr3)\n",
    "\n",
    "# Generate a random integer\n",
    "r1 = np.random.randint(1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can discover many more algorithms that numpy supports here:\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Application and Review\n",
    "\n",
    "> Let's use numpy to simulate coin flips and dice rolls.\n",
    "\n",
    "Assume you flip 5 fair coins (i.e. the probability of a coin landing on one side is 0.5). Write a small function which will determine the _estimated probability_ that at most 3 coins will be heads or exactly 1 coin lands on heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_coins():\n",
    "    trials = 100000\n",
    "    results = 0\n",
    "    # ... write a function which determine the estimated probability\n",
    "    # that at most 3 coins will be heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge problem\n",
    "# Write a function which takes N dice and returns the estimated probability\n",
    "# that the total score is greater than 11 or odd\n",
    "\n",
    "## WRITE YOUR SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "Given a set of data, we can use a few techinques to determine the \"shape\" of the data.\n",
    "\n",
    "Assume we have the following set of data $X = \\{x_1, x_2, x_3, ..., x_n\\}$.\n",
    "\n",
    "> **arithmetic mean**\n",
    "The arithmetic mean is defined as $\\overline{X} = \\frac{1}{n}(x_1 + x_2 + x_3 + ... + x_n)$\n",
    "    \n",
    "> **median**\n",
    "The median is defined as the $M = x_{\\frac{n}{2}}$ if $n$ is odd. Otherwise, we take the average of the middle two numbers in an _ordered_ set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "samples = 100\n",
    "nrml_data_set = np.random.normal(0, 0.1, samples)\n",
    "\n",
    "# scan the documentation for the `mean` and `median` functions calculate the mean and median\n",
    "\n",
    "# Do you notice anything about the mean and the median?\n",
    "\n",
    "# Using the np.random.normal function, generate a few datasets and compare the median and mean\n",
    "# for each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance of a dataset measure how **spread apart** the data are from eachother.\n",
    "\n",
    "Which histograms do you think display _high variance_, which have _low variance_?\n",
    "![variance example](https://qph.fs.quoracdn.net/main-qimg-e58c4ef2d7591f651e6f6e19d8550fae)\n",
    "\n",
    "Formally, we calculate the variance as the _normalized sum of the squares of each data's magnitude from the mean_. In other words, we:\n",
    "    1. look at every data point\n",
    "    1. calculate how far away it is from the mean\n",
    "    1. square each difference and sum them all together\n",
    "    1. normalize by the total number of data points\n",
    "    \n",
    "$$\n",
    "\\sigma^2 = \\frac{\\sum{(x_i - \\overline{x})^2}}{n}\n",
    "$$\n",
    "\n",
    "> **Notice** that the variance is in squared units. People will often take the square root of the variance in order to have a quantity with the same unit as the mean. We call this value the _standard deviation_.\n",
    "\n",
    "$$\n",
    "\\text{SD}  = \\sqrt{\\sigma^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use another library called pandas to load in our data.\n",
    "# Pandas is built on top of numpy and supports it's functionality\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./data/salaries.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ce015700360a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msalary_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/salaries.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Examine the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalary_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/my_env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/my_env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/my_env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/my_env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/my_env/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./data/salaries.csv' does not exist"
     ]
    }
   ],
   "source": [
    "salary_data = pd.read_csv('salaries.csv', low_memory=False)\n",
    "\n",
    "# Examine the data\n",
    "list(salary_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the TotalPay column into an array so we may analyze it\n",
    "total_pay = salary_data.loc[:,\"TotalPay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean, median, variance and standard deviation of\n",
    "# the total pay and base pay data sets\n",
    "\n",
    "## WORK HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias\n",
    "\n",
    "In reality, whenever we collect data, there is an inherent randomness. If you repeat an experiment many times, you may get slightly different data every time. The error will not be corrected if we average out these results, and we call this error **bias**.\n",
    "\n",
    "\n",
    "**In other words:**\n",
    "\n",
    "_Bias_ is what happens when we fail to take information into account or have incorrect assumptions. \n",
    "\n",
    "> Discussion time. Can you think of examples of how bias may have affected our salary data set above?\n",
    "\n",
    "### Overfitting and Underfitting\n",
    "\n",
    "When we build models, we want to build models which are specific enough that they yield relevant predictions, but also general enough that they can be applied to new an unseen datasets.\n",
    "\n",
    "If a model is too specific to the data, we are unable to generalize the results, and we call this **overfitting**\n",
    "\n",
    "If a model is not specific enough to yield meaningful predictions, we call this **underfitting**\n",
    "\n",
    "> regression models\n",
    "\n",
    "![fit curves](https://qph.ec.quoracdn.net/main-qimg-b4112b5d856f4f0da349460aeed854d8)\n",
    "\n",
    "> classification models\n",
    "\n",
    "![more fit curves](https://cdncontribute.geeksforgeeks.org/wp-content/uploads/fittings.jpg)\n",
    "\n",
    "> Discussion time.\n",
    "\n",
    "    - Why is underfitting and overfitting undesirable?\n",
    "    - Can you think of ways that we may inadvertently overfit data?\n",
    "    - How might we underfit data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Variance Tradeoff\n",
    "\n",
    "> IMPORTANT!!\n",
    "\n",
    "There is a fundamental property which states that error of a model is directly related to the sum of the **variance** and the **bias**^2.\n",
    "\n",
    "![variance tradeoff](https://www.researchgate.net/profile/Ljubomir_Jacic2/post/How_does_model_complexity_impact_the_bias-variance_tradeoff/attachment/59d6233579197b807798188f/AS%3A306150770184192%401450003439733/image/biasvariance.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
