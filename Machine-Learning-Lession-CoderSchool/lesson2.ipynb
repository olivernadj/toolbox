{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 - Fundamentals (part 2)\n",
    "\n",
    "**Prereading**\n",
    "\n",
    "[statistical distributions (https://blog.cloudera.com)](https://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/)\n",
    "\n",
    "**Goal**\n",
    "\n",
    "After this lesson, you should:\n",
    "1. Know how to setup a working python environment on your computer using anaconda\n",
    "2. Understand the following concepts:\n",
    "    - probability distributions\n",
    "    - central limit theorem\n",
    "    - covariance\n",
    "    - correlation / causation\n",
    "    - hypothesis testing\n",
    "    - p-value\n",
    "   \n",
    "-----\n",
    "\n",
    "#### Some notes from Lesson 1 - (Part 1)\n",
    "\n",
    "I received some feedback on the pace and structure. \n",
    "> What math/programming is required for this course?\n",
    "- A foundational background in highschool probability/statistics.\n",
    "- A intro level undergraduate statistics course would be helpful.\n",
    "- Experience with at least 1 other high level programming langauge (e.g. Python, Ruby, C#, etc...)\n",
    "\n",
    "Some resources to help refresh on these concepts:\n",
    "\n",
    "- https://www.khanacademy.org/math\n",
    "- https://www.khanacademy.org/math/statistics-probability\n",
    "- http://www.henry.k12.ga.us/ugh/apstat/chapternotes/7supplement.html\n",
    "- https://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/\n",
    "- https://www.learnpython.org/\n",
    "\n",
    "## Recap and Quick Overview on Distributions\n",
    "\n",
    "From last lesson, recall:\n",
    "\n",
    "$$\n",
    "    Err(x) = \\text{Bias}^2 + \\sigma^2 + \\text{Irreducible Error}\n",
    "$$\n",
    "\n",
    "This is the *bias-variance tradeoff*, and it says that there is a tradeoff when building a model between the strength of our assumptions and the complexity of our model.\n",
    "\n",
    "![BV image](https://www.kdnuggets.com/wp-content/uploads/bias-and-variance.jpg)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing the pre-reading, you should all have more familiary with some of the most common distributions. Let's refresh on some of these concepts and use python to generate the more common distributions.\n",
    "\n",
    "### Discrete vs Continuous\n",
    "\n",
    "> A **discrete** variable is one which may be counted (e.g. # of coin flips)\n",
    "\n",
    "> A **continuous** variable is one which may be measured (e.g. max height of a coin flip)\n",
    "\n",
    "**Bernoulli**\n",
    "\n",
    "$\n",
    "    bern(p) = \\cases{p, & \\text{if $x = 1$} \\\\ 1 - p, &\\text{if $x = 0$}}\n",
    "$\n",
    "\n",
    "$\\mu:p$\n",
    "\n",
    "$\\sigma^2:p(1-p)$ \n",
    "\n",
    "*Example: The French national team will win the world cup, or they won't.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binomial**\n",
    "\n",
    "$\n",
    "    binom(n,p) = \\cases{\\binom{n}{k}p^k(1-p)^{n-k} \\quad\\text{for $0 \\leq k \\leq n$}}\n",
    "$\n",
    "\n",
    "$\\mu:np$\n",
    "\n",
    "$\\sigma^2:np(1-p)$\n",
    "\n",
    "*Example: After lowering the price of your product, sales either increase or they do not*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geometric**\n",
    "\n",
    "$\n",
    "    geom(p) = p(1-p)^{k-1} \\quad\\text{for $k=1,2,...$}\n",
    "$\n",
    "\n",
    "$\\mu: \\frac{1}{p}$\n",
    "\n",
    "$\\sigma^2: \\frac{1 - p}{p^2}$\n",
    "\n",
    "*Example: You ask people in an electronics store whether they want to purchase an Asus computer until you find someone who says, \"yes.\" The geometric distribution represents the number of people you needed to ask before someone said \"yes.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Poisson**\n",
    "\n",
    "$\n",
    "    poiss(\\lambda) = \\frac{e^{-\\lambda}\\lambda^{x}}{x!} \\quad\\text{for k=1,2,...}\n",
    "$\n",
    "\n",
    "$\\mu:\\lambda$\n",
    "\n",
    "$\\sigma^2:\\lambda$\n",
    "\n",
    "*Example: The number of patrons who visit a restaurant per hour. If the restaurant gets (on average) X patrons per hour, the actual amount is variable and likely ascribes to a Poisson distribution.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uniform**\n",
    "\n",
    "$\n",
    "    unif(a,b) = \\frac{1}{b-a} \\quad\\text{ for every $x$ in the interval $(a,b)$}\n",
    "$\n",
    "\n",
    "$\\mu: \\frac{a+b}{2}$\n",
    "\n",
    "$\\sigma^2: \\frac{(b-a)^2}{12}$\n",
    "\n",
    "*Example: Someone waiting for a bus which comes every hour. He doesn't know the last time the bus arrived, but he knows it will arrive within the next hour.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal**\n",
    "\n",
    "$\n",
    "    norm(\\mu,\\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n",
    "$\n",
    "\n",
    "$\\mu: \\mu$\n",
    "\n",
    "$\\sigma^2: \\sigma^2$\n",
    "\n",
    "*Example: Many people argue that almost nothing is truly normally distributed, but the Central Limit Theorem allows us to view the means of any crazy distribution as asymptotically normal. However, resting body temperature is a good example to view something approximately normal.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exponential**\n",
    "\n",
    "$\n",
    "    exp(\\lambda) = \\lambda e^{-x\\lambda} \\quad\\text{$x \\geq 0, \\lambda > 0$}\n",
    "$\n",
    "\n",
    "$\\mu: \\frac{1}{\\lambda}$\n",
    "\n",
    "$\\sigma^2: \\frac{1}{\\lambda^2}$\n",
    "\n",
    "*Example: The time it takes a bank teller to serve a customer. (any example which arises by the waiting time in a homogenous Poisson process)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem\n",
    "\n",
    "> The sampling distribution tends to look normal.\n",
    "\n",
    "This is important because it says that, given certain conditions, you can approximately almost any distribution with the normal distribution, even if the underlying distribution is not normal.\n",
    "\n",
    "Specifically, $\\bar{X} \\sim Normal\\big(\\mu,\\frac{\\sigma^2}{n}\\big)$, and the derived standard variable $Z = \\frac{\\bar{X}-\\mu}{\\sigma\\space\\space/\\sqrt{n}}$. In other words, this describes the standard deviation of sample means given multiple samples from an underlying distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the Central Limit theorem using math SAT scores located in ./data/scores.csv\n",
    "# first, we will import scipy\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance & Correlation\n",
    "\n",
    "**Covariance** measures how two random variables change together. When calculating a covariance matrix, the data is not standardized, and thus you cannot use the covariance statistic to assess the strength of a linear relationship. You can only infer that a relationship exists.\n",
    "\n",
    "> Discussion, why might covariance be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examining covariance using SAT scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation** measures how two random variables are related. There are multiple ways of measuring correlation, but for now, it sufficies to say that there exists a special number called the *correlation coefficient*, which provides a measure of the linear relationship between two random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now examine correlation in SAT scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "The primary purpose of statistics is to test a *hypothesis*. A **hypothesis** is a statement about an observation. When we propose a hypothesis we need to *test* that hypothesis against some data.\n",
    "\n",
    "In machine learning, we will often want to compare two models against one another or the same model against itself with different configurations. If the expected performance of two different models, how do we know that the difference is significant? What does it even mean to be signficant?\n",
    "\n",
    "#### Terminology\n",
    "\n",
    "- **null hypothesis H$_0$**: A default position that there is no relationship between two measured random variables.\n",
    "\n",
    "- **alternative hypothesis H$_A$**: The rival hypothesis which claims relationship between two measured random variables.\n",
    "\n",
    "- **test statistic**: A sample used to determine whether the alternative hypothesis is rejected or accepted. The test statistic measures the agreement between a sample of data and the null hypothesis.\n",
    "\n",
    "- **significance level $\\alpha$**: A probability threshold which admits the alternative hypothesis. Specifically, *it is the probability of rejecting the null hypothesis when it is true.* For example, $\\alpha = .05$ means there is a $5\\%$ risk of saying there is a signficant result, when in reality there is no difference.\n",
    "\n",
    "- **p-value**: The probability of obtaining an effect at least as extreme as the one in the sample data, assuming the null hypothesis is true.\n",
    "\n",
    "Let's understand significance level a little more. Consider the following graph with $\\alpha = 0.5$. We see that the 5% of the distribution furthest from the null hypothesis is shaded. If we have a sample mean of $330.6$ which falls in the *critical region*, it means it is statistically significant at the 5% threshold.\n",
    "\n",
    "![sig graph](https://blog.minitab.com/hubfs/Imported_Blog_Media/sig_level_05.png?t=1531941588303)\n",
    "\n",
    "So what's a p-value? Consider the same sample mean of $330.6$. We determine the distance from the null hypothesis and then consider the probability of obtaining a sample mean which is *at least as extreme* in both tails of the distribution $(260 \\pm 70.6)$. This probability represents the likelihood of getting a sample mean that is at least as extreme as our sample mean in both tails. That is the p-value!\n",
    "\n",
    "![pvalue graph](https://blog.minitab.com/hubfs/Imported_Blog_Media/p_value.png?t=1531941588303)\n",
    "\n",
    "\n",
    "### Methodology\n",
    "\n",
    "1. State $H_0$ and $H_A$.\n",
    "2. State any assumptions about the sample or the distributions\n",
    "3. Choose a significance level $\\alpha$\n",
    "4. Compute the appropriate *test statistic* using the collected data\n",
    "5. Compute the *p-value* based on the test statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to apply the above methodology to an analysis of the mean of SAT math scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type 1 and Type 2 Errors\n",
    "\n",
    "So, we've used the above methodology to determine the validity of our hypothesis. Now what? Well, we could always be wrong...\n",
    "\n",
    "|                |  $H_0$ is true   | $H_0$ is false   |\n",
    "|----------------|------------------|------------------|\n",
    "| Accept $H_0$   | Correct Decision ($1-\\alpha$) | Type 2 Error ($\\beta$)       |\n",
    "| Regeject $H_0$ | Type 1 Error ($\\alpha$)       | Correct Decision ($1-\\beta$) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
